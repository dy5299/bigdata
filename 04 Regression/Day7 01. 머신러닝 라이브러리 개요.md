# 01. 머신러닝 라이브러리 개요

## 기계학습의 구분

### 학습 방법의 구분

#### 지도 학습 (Supervised Learning)

- 데이터에 정답이 존재하여,이 정답을 기반으로 학습한다.
- 이 정답을 레이블(label) 또는 클래스(class)라고 한다.
- 지도 학습의종류
  - 회귀 분석
  - 분류 (의사결정 나무, 랜덤 포레스트, SVM 등)
  - 대부분의 기존 신경망

#### 비지도 학습 (Unsupervised Learning)

- 데이터에 정답이 없어서, 아무런 도움 없이 학습한다.
- 비지도학습의 종류
  - 군집화
  - PCA
  - 패턴 탐사 (연관규칙, 빈발항목집합 등)

## 사이킷런 (Scikit-learn)

### 사이킷런

- 대표적인 파이썬 머신러닝 라이브러리로서, 회귀 분석을 비롯하여 다양한 분석 알고리즘과 기능들을 제공한다.
- 웹사이트 https://scikit-learn.org 에서 관련 정보 및 문서, 예제 등을 확인할 수 있다.
- 아나콘다를 설치하면 자동적으로 사이킷런까지 설치되므로 별도의 추가 설치 또는 설정 없이 사용할 수 있다.
- 만약 별도로 재설치하고자 할 경우에는 Anaconda Prompt 에서 다음 명령어 중 하나를 입력하여 설치한다.
  - pip install scikit-learn
  - conda install scikit-learn

### 주요 모듈들의 개요

구분 모듈명 설명
예제
데이터
sklearn.datasets 사이킷런에내장되어있는
예제데이터들
전처리
및
특성처리
sklearn.preprocessing 데이터의정규화, 스케일링
등전처리및가공기능
sklearn.feature_selection 분석수행과관련된특성
값들에대한처리기능
데이터분리
및검증
sklearn.model_selection 학습용/검증용데이터분리,
매개변수조정기능
성능 평가 sklearn.metrics 분석결과에대한성능측정
및평가기능

구분 모듈명 설명
분석기법
(알고리즘)
sklearn.linear_model 회귀 분석 (선형 회귀, 릿지,
라쏘, 로지스틱회귀등)
sklearn.svm 서포트 벡터 머신 sklearn.tree 의사 결정 나무 sklearn.ensemble 앙상블기법(랜덤포레스트,
에이다부스트등)
sklearn.cluster 군집화 (K-means, DBSCAN 등)

### 내장 예제 데이터



### 학습/검증 데이터 분리



### 사이킷런의 분석 수행 절차

① 분석을 수행하기 위한 추정자(Estimator) 객체를 생성한다.

② 생성된 객체에 대하여 fit 메소드(함수)를 호출하여 학습을 수행한다.

③ 생성된 객체 또는 학습이 수행된 분석 결과에 대하여 predict 메소드(함수)를 호출하여 예측 결과를 도출한다.

④ 생성된 객체 또는 학습이 수행된 분석 결과에 대하여 적합한 성능 평가 지표를 도출한다.

## Statsmodels

- 다양한 통계 검정 및 추정, 회귀 분석, 시계열 분석 기능을 제공하는 통계 분석 라이브러리이다.

- 아나콘다를 설치하면 자동적으로 스탯츠 모델이 설치되므로 별도의 추가 설치 또는 설정 없이 사용할 수 있다.

- 기존의 R Studio에서 제공하는 것과 동일한 명령어들을 이용하여 통계 분석과 시계열 분석, 검정 통계량 계산 등을 수행할 수 있다.

- 따라서, 회귀 분석(OLS) 또는 주성분 추출(PCA) 등의 기법은 상황에 따라 사이킷런 외에 스탯츠 모델을 이용하여 수행하는 것도 무방하다.

- 분석 기법들은 서브 모듈 api를 이용한다.

  ```python
  import statsmodels.api as sm
  ```

  # 02. 단순 선형 회귀

## 회귀 분석

### Regression

- 데이터의 값은 평균과 같은 기존의 경향으로 돌아가려는 경향이 있다는 것
- 여러 변수들 간의 상관 관계를파악하여,어떤 특정 변수의 값을 다른 변수들의 값을 이용하여 설명/예측하는기법

### 회귀 분석의 유형

- 변수의 개수 및 계수의 형태에 따라 구분한다.
- 독립변수의 개수에 따라
  - 단순 : 독립변수가 1개인 경우
  - 다중 : 독립변수가 여러 개인 경우
- 회귀계수의 형태에 따라
  - 선형 : 계수를 선형 결합으로 표현할 수 있는 경우
  - 비선형: 계수를 선형 결합으로 표현할수 없는 경우

## 단순 선형 회귀

### Simple Linear Regression

- 독립변수가 1개이고 종속변수도 1개인 경우, 그들 간의 관계를 선형적으로 파악하는 회귀 방식
- 독립변수 X와 종속변수 Y의 관계를 Y = aX + b 형태의 1차 함수식으로 표현할 수 있다.
- 회귀 계수 (coefficient)
  - 독립변수가 종속변수에끼치는영향력의 정도로서, 직선의 기울기(slope)
- 절편 (intercept)
  - 독립변수가 0일 때의 상수 값
- 잔차 (residual)
  - 실제 값과 회귀식의 차이에 따른 오류 값
  - 잔차 값이 작을수록, 구해진 회귀식이 데이터들을 더욱 잘 설명하고 있다고 볼 수 있다.
- 잔차제곱합 (RSS; Residual Sum of Squares)
  - 잔차는 양수 또는 음수가 될 수 있는 값이므로 이들을 단순히 더하면 안 되고, 이 값들의 제곱을 구해서 더한다.
    (이 때, xi는 독립변수 집합 X의 원소, yi는 종속변수 집합 Y의 원소이다.)
  - 이 때, RSS를 회귀 분석에서의 손실 함수(loss function) 또는 비용 함수(cost function)라고 한다.
- 최적의 회귀 모형을 만든다는 것은 RSS 값이 최소가 되는 회귀 계수를 구한다는 의미이다.

> 엄밀히 말하면 오류(error)와 잔차(residual)는 다르다.
>
> 잔차: 오류를 감안하고도 남은 오류
>
> 결정계수(R^2)는 0.65만 되어도 충분. 0.9가 나왔다? 치명적인 조작임.

## 회귀 분석의 평가 지표

### 회귀 분석 결과에 대한 주요 평가 지표

### 결정 계수 (Coefficient of Determination)

- 회귀식이 얼마나 설명력이 있는지 (즉, 얼마나 정확한지) 나타내는 지표이다.
- 결정 계수의 값은 0 ≤ R2≤ 1이며, 1에 가까울수록 설명력이 강하고 0에 가까울수록 설명력이 약하다.
- 일반적으로 결정 계수 R2의 값이 0.65 (65%) 이상이면 설명력이 있다고 판단한다.

### 최소제곱법 (OLS; Ordinary Least Squares)

- 잔차제곱합 RSS 값이 최소화 되도록 손실 함수의 매개변수 w0와 w1의 값을 구한다.
- w0와 w1으로 RSS 함수를 각각 편미분한 값이 0이 되는 연립 방정식의 해를 구한다.